{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvVQkYGnNTaTQ+4bimHap6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdexbarr/Neural-networks/blob/main/RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a446ZGN-HyAG"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training text\n",
        "text= \"\"\"\n",
        "A neural network is a machine learning model that is inspired by the way biological neural networks in the human brain work. These models are composed of interconnected nodes organized in layers; these nodes are called neurons which process information by transforming inputs into outputs through mathematical operations.\n",
        "\n",
        "Neural networks are of great importance because they allow the identification of complex patterns and the recognition of deep relationships within data. Furthermore, they can learn to manage large amounts of information efficiently, contributing to increased productivity, supporting automated decision-making systems, and optimizing workflows and processes. It can be said that neural networks represent one of the pillars of artificial intelligence.\n",
        "\n",
        "Neural networks are capable of learning and identifying patterns from given data without the need for predefined rules. Neural networks have three components:\n",
        "\n",
        "1. Neurons: This is the fundamental unit of a neural network. Each neuron within a network receives an input, processes it using a weighted sum, applies an activation function, and produces an output.\n",
        "\n",
        "2. Weights: Parameters that the neural network learns during training. These weights help determine the strength of connections between different neurons.\n",
        "\n",
        "3. Bias: Bias is an additional parameter that allows neurons to adjust their outputs independently of the inputs.\n",
        "\n",
        "4. Learning Rule: The method used to adjust the weights and bias over time to improve accuracy.\n",
        "\n",
        "5. Connections: Links between neurons that transmit information, regulated by weights and biases.\n",
        "\n",
        "6. Propagation Functions: Mechanisms that help process and transfer data across the layers of neurons.\n",
        "\n",
        "Neural networks follow a three-stage learning process:\n",
        "\n",
        "Input Computation: Data is fed into the neural network.\n",
        "\n",
        "Output Generation: Based on parameters, the network generates an output.\n",
        "\n",
        "Iterative Refinement: Adjustment of the weights and biases to refine the network, gradually improving performance on various tasks\n",
        "\n",
        "EXAMPLE: I made a simple neural network to predict the price of a house based on the size, the number of rooms and the distance from downtown. I used synthetic prices to make it simple. The model  learned to estimate an approximate price using two dense layers with ReLU activation. I recorded the error during both training and data validation, and then graphed how the mean squared error (MSE) evolves with each iteration to visualize the model's improved performance. Finally, the network makes a prediction about a new house\n",
        "\n",
        "2)\n",
        "\n",
        "\n",
        "Feedforward Neural Networks:\n",
        "\n",
        "Information flows in one direction without forming any cycles between layers or nodes, the data can pass through those nodes within the hidden level to the output nodes.\n",
        "\n",
        "This category is made up of layers with unidirectional flow of data, which means that goes from input through hidden and the output layer. Backpropagation is used during the training of this type of neural networks with the purpose of reducing error in predictions.\n",
        "\n",
        "Have several applications, but It is mainly used for pattern recognition tasks like image and speech classification. Its ideal to use when the data is static and has no sequential dependencies\n",
        "\n",
        "Example: Classify flowers using iris dataset\n",
        "\n",
        "Convolutional Neural Networks (CNNs):\n",
        "\n",
        "Convolutional neural networks are designed with the purpose of extracting features from grid-like matrix datasets. Particularly used for processing of grid type data like images and videos where the data patterns have a crucial role. Their key components are: convolutional layers, pooling layers and fully connected-layers.\n",
        "\n",
        "They are used for working with classifications of images and videos, object detection autonomous driving and visualization in augmented reality\n",
        "\n",
        "it has some advantages:\n",
        "Is good detection patterns and features son visual data such as, images, videos and audio signals\n",
        "Theres no need for manual feature extraction since is a End-to-end training\n",
        "Able to manage large amounts of data and still get a high accuracy\n",
        "\n",
        "Disadvantages:\n",
        "Computationally expensive, and expensive in general since it requires a lot of money\n",
        "Requires large amounts of labeled data\n",
        "Prone to overfitting\n",
        "\n",
        "Example: Determine whether an image of an MNIST digit is even or odd\n",
        "\n",
        "This program trains a CNN  to determine if a MNIST digit is even or odd. First, normalize the images and the transform the labs of the digits to 0 for even and 1 for odd. Then the cnn is build with two convolutional layers that would be trained for a couple of epochs, and finally the model is evaluated on the test set. Also it graphs the process of learning of the model\n",
        "\n",
        "Neural networks are computational models inspired by the structure and function of the human brain.\n",
        "The architecture of neural networks is organized in layers, which define how information flows within the system and what different types of transformations are applied to the data at each stage. At the simplest architectural levels, we can see that neural networks consist of an input layer, one or more hidden layers, and an output layer. However, depending on the type of neural network applied, some go beyond this basic structure to process different types of data such as images, text, audio, or audio signals. Each category of neural network has a distinct architecture adapted to solve specific problems by leveraging unique structural properties, whether spatial, relational, or temporal.\n",
        "\n",
        "Input Layer\n",
        "This is the initial layer of a neural network and is responsible for the entry point of raw data. No calculations are performed here; it simply receives the raw inputs. For example, the pixel values ​​of an image, or numerical features. The function of this layer is to pass this data to the subsequent layers within the network, preserving the structure and dimensions for future processing.\n",
        "\n",
        "Convolutional Layer:\n",
        "\n",
        "This layer is found in convolutional neural networks (CNNs) as it is their core component. This layer focuses on applying filters to the input data to extract features in order to detect patterns, such as edges, textures, shapes, or other complex visual features. One of these filter layers generates a feature map by performing element-by-element multiplications and then summing the results. This gives us a map that highlights specific patterns, such as edges, and allows the neural network to learn the spatial hierarchy of patterns. Convolutional layers are beneficial because they greatly help reduce the number of parameters required, thus helping to preserve the relevant and essential information in the input.\n",
        "\n",
        "\n",
        "Hidden Layer:\n",
        "\n",
        "Hidden layers are layers located between the input and output layers in the architecture of neural networks. Within these layers, calculations and transformations of data obtained from the previous layer are performed using weights and biases, enabling the network to learn complex patterns. Depending on the structure, these layers can be fully connected or have specialized layers. The greater the number of hidden layers, the deeper the network, allowing for more precise feature extraction and higher performance on complex tasks.\n",
        "\n",
        "\n",
        "Pooling Layer:\n",
        "Pooling layers are frequently used after convolutional layers. They help reduce the size of the feature maps generated by convolutional layers, thereby decreasing computational complexity and memory requirements while preserving the most relevant features. Common operations in this layer include maximum pooling, which selects the maximum value from a region, and average pooling, which takes the average value from a region. Pooling serves to represent the input more abstractly while maintaining essential features.\n",
        "\n",
        "\n",
        "Stride Layer:\n",
        "\n",
        "The stride refers to a parameter associated with the pooling and convolutional layers, which determines the positions the filter will move within these two layers. The stride defines the step size by which the pooling filter will move across the input. A stride of 1 means the filter moves 1 pixel, while 2 strides means one pixel is skipped and the other is not, thus reducing the output size. The stride influences the reduction of spatial dimensions and the total amount of computation required; the higher the stride, the smaller the resulting feature maps.\n",
        "\n",
        "Activation Layer:\n",
        "The activation layer applies nonlinear activity functions to the output of the previous layer. Without these activation functions, neural networks would act as simple, linear models incapable of learning complex patterns. By using activity functions, nonlinearity is introduced into the network, allowing it to learn complex relationships within the data and identify distinct patterns. The most common activity functions are ReLU, sigmoid, and hyperbolic tangent (tanh). Using these enables the network to learn features, make decisions, and model nonlinear relationships in the real-world context.\n",
        "\n",
        "Normalization Layer:\n",
        "Normalization layers are responsible for adjusting and standardizing the inputs in subsequent layers to address problems such as internal covariate shifting. This is done to scale activations during training and accelerate learning. An example is batch normalization, which normalizes outputs to maintain a consistent distribution throughout the network. This also helps improve gradient flow, optimize generalization, and even enhance model performance.\n",
        "\n",
        "\n",
        "Dropout Layer:\n",
        "\n",
        "The dropout layer is responsible for a regularization technique to prevent mismatch problems. It randomly deactivates a percentage of neurons in each layer during each training step. This trains the neural network to function independently of specific neurons and forces it to learn more robust features, all to reduce mismatch in the model. By forcing the model to learn more robust features, dropout improves generalization and even performance with non-given data.\n",
        "\n",
        "Output Layer:\n",
        "The output layer is responsible for delivering the final product; it's where the network's prediction or output is generated. The structure of this layer depends on the task being performed. For binary classification, it will consist of a single neuron; for multiclass classification, it will use multiple neurons with SoftMax; or for regression, it will have multiple outputs. This layer transforms all the features learned in the previous layers to produce a final prediction or decision.\n",
        "\n",
        "\n",
        "\n",
        "4)\n",
        "\n",
        "An activation function in neural networks consists of mathematical functions applied to a neuron's output to introduce nonlinearity. This allows the model to be nonlinear and simple, enabling it to form curved decision boundaries, making it capable of learning and representing complex data patterns. Without this activation function, it would be a simple linear regression model, meaning that no matter how deep the network is, it would only be able to learn simple patterns.\n",
        "\n",
        "These activation functions determine whether a neuron should be activated or not, based on a weighted sum of the inputs and a bias term. If this mathematical operation determines that the neuron should be activated, the function transforms that sum into a nonlinear output. Furthermore, these functions enable backpropagation by providing gradients to update the weights.\n",
        "\n",
        "There are different types of activation functions.\n",
        "\n",
        "Among them, we find linear activation functions:\n",
        "\n",
        "This function resembles a straight line defined by y = x.\n",
        "\n",
        "In this type of activation function, regardless of the number of layers in the neural network, if all neurons use linear activation functions, the output will be a linear combination of the input.\n",
        "\n",
        "The output range extends from\n",
        "\n",
        "(−∞ to +∞).\n",
        "\n",
        "The linear activation function is used only in the output layer.\n",
        "\n",
        "Using linear activation in all layers limits the network's ability to learn complex patterns.\n",
        "\n",
        "\n",
        "Next, we can find the nonlinear activation functions.\n",
        "\n",
        "Here we can find the three most popular: ReLU, sigmoid, and hyperbolic tangent (tanh).\n",
        "\n",
        "Sigmoid:\n",
        "\n",
        "The sigmoid activation function is characterized by its \"S\" shape. It is mathematically defined as: A= 11+e-x\n",
        "\n",
        "This formula guarantees a smooth and continuous output, which is mostly used for gradient-based optimization methods. This activation function allows neural networks to handle complex patterns that linear equations cannot.\n",
        "\n",
        "The output of this activation function varies between 1 and 0, making it very useful for binary classification problems. The function exhibits a steep gradient when the x values ​​are between -2 and 2. This sensitivity means that small changes in the x input can lead to significant changes in the output, which would not be beneficial during the training process; instead, it can be considered critical.\n",
        "\n",
        "\n",
        "Hyperbolic:\n",
        "\n",
        "The hyperbolic tangent function (tanh) is a shifted version of the sigmoid function, allowing it to extend along the y-axis. It is defined as:\n",
        "\n",
        "f(x) = tanh(x) = 21+e-x-1\n",
        "\n",
        "Alternatively, it can be expressed using the sigmoid function:\n",
        "\n",
        "tanh(x) = 2 × sigmoid(2x) − 1\n",
        "\n",
        "It generates values ​​within the range of -1 to +1.\n",
        "This activation function is nonlinear, which allows for modeling complex data patterns.\n",
        "It facilitates learning for subsequent layers due to its zero-centered output, which is also why this function is commonly placed in hidden layers.\n",
        "\n",
        "\n",
        "ReLU (Rectified Linear Unit) Function\n",
        "\n",
        "\n",
        "A(x) = max(0, x), meaning that if the input x is positive, ReLU returns x; if it is negative, it returns 0.\n",
        "\n",
        "Value range: [0, ∞), only returns non-negative values.\n",
        "\n",
        "It is a non-linear activation function, which allows neural networks to learn complex patterns and enables more efficient backpropagation.\n",
        "\n",
        "ReLU is less computationally expensive than the hyperbolic tangent (tanh) and sigmoid functions because it involves simpler mathematical operations. Only a few neurons are activated at a time, making the network sparse, efficient, and easy to compute.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A neural network is a model of neurons inspired by the human brain. It is composed of many interconnected neurons. Deep learning, on the other hand, is distinguished by the depth or number of hidden layers it possesses.\n",
        "\n",
        "They have different architectures. Neural networks typically have architectures such as feedforward neural networks, recurrent neural networks, and symmetrically connected neural networks, while deep learning networks have architectures such as recursive neural networks, pre-trained unsupervised networks, and convolutional neural networks.\n",
        "\n",
        "Generally, neural networks require less training time but have lower accuracy than deep learning systems. In contrast, deep learning requires more training time and has higher accuracy than neural networks.\n",
        "\n",
        "Neural networks offer lower performance compared to deep learning systems, which provide higher performance. There's also a difference in how they interpret tasks. Neural networks interpret tasks poorly, while deep learning networks perceive your task more effectively.\n",
        "\n",
        "Neural networks can be excellent tools for addressing a variety of issues, including classification, pattern recognition, prediction and analysis, clustering, decision making, and machine learning. Deep learning, on the other hand, can be excellent tools for more complex problems, such as pattern recognition, speech recognition, natural language processing, computer games, self-driving cars, social network filtering, and more\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\"Text length:\", len(text))\n",
        "print(\"Example test:\\n\", text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0-xfQfrH5jE",
        "outputId": "2c27fad3-533a-498d-93b6-459537cce7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text length: 15324\n",
            "Example test:\n",
            "  \n",
            "A neural network is a machine learning model that is inspired by the way biological neural networks in the human brain work. These models are composed of interconnected nodes organized in layers; th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of vocabulary for the characters\n",
        "chars = sorted(list(set(text)))\n",
        "vocabulary_size = len(chars)\n",
        "\n",
        "# char2idx converts each character to its index using enumerate\n",
        "#idx2char does the reverse mapping, from index to character\n",
        "\n",
        "char2idx = {c: i for i, c in enumerate(chars)}\n",
        "idx2char = {i: c for i, c in enumerate(chars)}\n",
        "\n",
        "# codify the text to whole  numbers\n",
        "encoded_text = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "aWWBl0UfIZVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of the sequences, where x would be the input and Y would be the next character\n",
        "sequence_length = 40  # a put this length for the seuqence\n",
        "inputs = []\n",
        "targets = []\n",
        "\n",
        "for i in range(len(encoded_text) - sequence_length):\n",
        "    inputs.append(encoded_text[i:i+sequence_length])  # Extract a subsequence of length 40 from position\n",
        "    targets.append(encoded_text[i+sequence_length]) #Save the character following the sequence as the target\n",
        "\n",
        "inputs = np.array(inputs)\n",
        "targets = np.array(targets)\n",
        "\n",
        "print(\"inputs shape:\", inputs.shape)\n",
        "print(\"targets shape:\", targets.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3-daORYJKAU",
        "outputId": "5809b6ea-4f1d-4a24-efa1-b3374732464c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs shape: (15284, 40)\n",
            "targets shape: (15284,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Definition of the model\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(vocabulary_size, 64, input_length=sequence_length),\n",
        "    layers.LSTM(128),\n",
        "    layers.Dense(vocabulary_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "k4F83pTsJ3s6",
        "outputId": "1316a8c2-3d9f-4fd0-957a-7280cb03575c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "history = model.fit(\n",
        "    inputs,\n",
        "    targets,\n",
        "    epochs=30,\n",
        "    batch_size=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43_A7ITPKLrg",
        "outputId": "45e29441-06e5-4d7c-dc37-6a2a3b5de138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 128ms/step - loss: 3.4559\n",
            "Epoch 2/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 125ms/step - loss: 2.8371\n",
            "Epoch 3/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 2.5681\n",
            "Epoch 4/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - loss: 2.4155\n",
            "Epoch 5/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - loss: 2.3038\n",
            "Epoch 6/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 2.2127\n",
            "Epoch 7/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 2.1265\n",
            "Epoch 8/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 2.0742\n",
            "Epoch 9/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - loss: 1.9998\n",
            "Epoch 10/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.9490\n",
            "Epoch 11/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.8691\n",
            "Epoch 12/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.8299\n",
            "Epoch 13/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.7715\n",
            "Epoch 14/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.7410\n",
            "Epoch 15/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - loss: 1.6756\n",
            "Epoch 16/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.6291\n",
            "Epoch 17/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.5939\n",
            "Epoch 18/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.5592\n",
            "Epoch 19/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.5233\n",
            "Epoch 20/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4925\n",
            "Epoch 21/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4450\n",
            "Epoch 22/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4134\n",
            "Epoch 23/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 116ms/step - loss: 1.3898\n",
            "Epoch 24/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 1.3501\n",
            "Epoch 25/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.3104\n",
            "Epoch 26/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3119\n",
            "Epoch 27/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.2680\n",
            "Epoch 28/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.2615\n",
            "Epoch 29/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.2130\n",
            "Epoch 30/30\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.1992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate text\n",
        "\n",
        "def generate_text(model, start_string, gen_length=300):\n",
        "    \"\"\"\n",
        "    From a string it would generate text using the model\n",
        "    \"\"\"\n",
        "    # Initial text to indexes\n",
        "    input_eval = [char2idx.get(c, 0) for c in start_string]\n",
        "    generated = list(start_string)\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "        # take last seq_length chars\n",
        "        input_seq = input_eval[-sequence_length:]\n",
        "        if len(input_seq) < sequence_length:\n",
        "            # char índice 0\n",
        "            input_seq = [0] * (sequence_length - len(input_seq)) + input_seq\n",
        "\n",
        "        input_array = np.array([input_seq])\n",
        "\n",
        "        # predict the distribution of the next char\n",
        "        preds = model.predict(input_array, verbose=0)[0]\n",
        "\n",
        "        # get the index with higher chance\n",
        "        next_index = np.argmax(preds)\n",
        "        next_char = idx2char[next_index]\n",
        "\n",
        "        # add result\n",
        "        generated.append(next_char)\n",
        "        input_eval.append(next_index)\n",
        "\n",
        "    return \"\".join(generated)"
      ],
      "metadata": {
        "id": "zrQTAivCKZqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For running\n",
        "\n",
        "start = \"Neural networks \"\n",
        "generated_text = generate_text(model, start_string=start, gen_length=400)\n",
        "\n",
        "print(\"\\nGenerated text:\\n\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPDChpo6K59c",
        "outputId": "5d8746b2-3f02-40be-f1f2-e710da265cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated text:\n",
            "\n",
            "Neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function in the neural networks and activation function \n"
          ]
        }
      ]
    }
  ]
}